{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "4e5cc9cd14a5e608bf2d863faad644aeb9ebbfc8037fed5491b2f0d6970473f9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mlp for binary classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(235, 34) (116, 34) (235,) (116,)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "df = read_csv(path, header=None)\n",
    "# split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 0.957\n"
     ]
    }
   ],
   "source": [
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted: 0.978\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "source": [
    "WHAT IS RESPONSIBLE ARTIFICIAL INTELLIGENCE?\n",
    "\n",
    "Responsible AI is concerned specifically with establishing ethical principles and human values in order to reduce biases and promote fairness, facilitate interpretability and explainability of outcomes, and to ensure robustness and security (Barredo Arrieta et al., 2020;Sambasivan & Holbrook, 2018). The ultimate goal of building AI technologies based on responsible principles is to avoid dramatic negative consequences on human and societal well-being (Dignum, 2019).\n",
    "The Scope of responsible AI varries from one Organisation to another. While most focus mostly on defining what this entails for their organisation, the main focus should be on putting the principle of responsible AI into practice. This movement from Principles to Practice has increasingly become a struggle for many organisations as they underestimate the technical complexities and Scale of people and process change required to make this a reality.\n",
    "\n",
    "In April 2019, The European Commission's High-Level Expert Group on AI put forward four ethical principles for the design and deployment of lawful, ethical and robust AI systems, which are :\n",
    "-Respect for human autonomy\n",
    "-Prevention of harm\n",
    "-Fairness\n",
    "-Explicability"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "AI FAILS\n",
    "\n",
    "-In 2016, UBER tested its self-driving cars in San Francisco without taking permissions and approvals from the State. That is ethically and legally not right. Moreover, the internal documents of Uber stated that the self-driving car crossed around 6 red lights in the city during testing.\n",
    "\n",
    "This is one of the clear examples of AI gone wrong as Uber uses top-notch vehicle sensors and networked mapping software as well as a driver to take care if things go out of control.\n",
    "\n",
    "-In October 2020, Public Health England (PHE), the UK government body answerable for counting new COVID-19 cases, uncovered that almost 16,000 Covid cases went unreported between Sept. 25 and Oct. 2. Wondering why this happened? Well, data limitations on excel is the reason.\n",
    "\n",
    "PHE utilizes an automated process to move COVID-19 positive lab results as a CSV record into Excel formats utilized by announcing dashboards and for contact tracing. Sadly, Excel sheets can have a limit of 1,048,576 lines and 16,384 columns for each worksheet. In addition, PHE was posting cases in columns instead of rows. At the point when the cases surpassed the 16,384-section limit, Excel removed the 15,841 records at the bottom.\n",
    "\n",
    "This shortcoming didn’t forestall people who got tested from getting their test results, however it stymied contact tracing endeavors, making it harder for the UK National Health Service (NHS) to recognize and advise people who were in close contact with contaminated patients. \n",
    "\n",
    "-A leading facial-recognition technology recognized three-time Super Bowl champion Duron Harmon of the New England Patriots, Boston Bruins forward Brad Marchand, and 25 other New England proficient athletes as criminals. Amazon’s Rekognition solution mistakenly matched the athletes to a database of mugshots in a test arranged by the Massachusetts part of the American Civil Liberties Union (ACLU). Almost one-in-six players were wrongly distinguished. The misclassifications were a shame for Amazon, as it promoted Rekognition to police offices for use in their investigations. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "IMPLICATIONS OF AI FAILS\n",
    "\n",
    "From a data privacy perspective, sensitive data–like consumer financials or data relating to health, ethnicity, sexual orientation, or gender–tend to carry higher risk and therefore a greater potential for liability and harm. Additional real-world considerations for increased materiality also include threats to health, safety, and third parties, legal liabilities, and reputational damage.\n",
    "\n",
    "The legal principle of accountability, for instance, requires organisations to account for the risks arising from their processing of personal data –whether they are running a simple register of customers’ contact details or operating a sophisticated AI system to predict future consumer demand.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "HOW TO ENSURE RESPONSIBILITY IN AI/WIDER USE OF DATA\n",
    "\n",
    "Organisations need to centre their responsible AI principles on lawfulness,fairness and transparency.\n",
    "\n",
    "-Organisations must break down and separate each distinct processing operation, and identify the purpose and an appropriate lawful basis for each one, in order to comply with the principle of lawfulness.\n",
    "\n",
    "-Second, if Organisations use an AI system to infer data about people, in order for this processing to be fair, they need to ensure that the system is sufficiently statistically accurate and avoids discrimination; and\n",
    "considers the impact of individuals’ reasonable expectations.\n",
    "\n",
    "-Thirdly, Organisations need to be transparent about how they process personal data in an AI system, to comply with the principle of transparency.\n",
    "\n",
    "In general, as mentioned earlier, Organisations need to develop an internal framework with which they can monitor and review their Responsible AI principles and its practicability.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}